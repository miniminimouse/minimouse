def get_psi(
    baseline_data: pd.DataFrame,
    oot_data: pd.DataFrame,
    variables: List[str],
    n_bins: int = 10,
    bin_method: str = 'quantile',
    min_bin_pct: float = 0.05
) -> Dict[str, Dict]:
    """
    Calculate Population Stability Index (PSI) for detecting distribution shifts.
    
    PSI measures how much a variable's distribution has shifted between two samples.
    Used heavily in banking for model monitoring and validation.
    
    Parameters:
    -----------
    baseline_data : pd.DataFrame
        Reference dataset (usually development/training sample)
    oot_data : pd.DataFrame  
        Out-of-time validation dataset
    variables : List[str]
        List of variable names to calculate PSI for
    n_bins : int, default=10
        Number of bins for discretization
    bin_method : str, default='quantile'
        Binning method: 'quantile' or 'equal_width'
    min_bin_pct : float, default=0.05
        Minimum percentage threshold for bin adjustments
        
    Returns:
    --------
    Dict[str, Dict]
        Dictionary with variable names as keys, containing:
        - 'psi_value': float - Overall PSI score
        - 'interpretation': str - Risk level interpretation  
        - 'bin_analysis': pd.DataFrame - Detailed bin-level breakdown
        - 'baseline_stats': Dict - Baseline distribution stats
        - 'oot_stats': Dict - OOT distribution stats
    """
    
    if baseline_data.empty or oot_data.empty:
        raise ValueError("Both datasets must contain data")
    
    # check variables exist in both datasets
    missing_baseline = [var for var in variables if var not in baseline_data.columns]
    missing_oot = [var for var in variables if var not in oot_data.columns]
    
    if missing_baseline:
        raise ValueError(f"Variables missing from baseline data: {missing_baseline}")
    if missing_oot:
        raise ValueError(f"Variables missing from OOT data: {missing_oot}")
    
    results = {}
    
    print("=" * 60)
    print("POPULATION STABILITY INDEX RESULTS")
    print("=" * 60)
    
    for var in variables:
        try:
            baseline_vals = baseline_data[var].dropna()
            oot_vals = oot_data[var].dropna()
            
            if len(baseline_vals) == 0 or len(oot_vals) == 0:
                warnings.warn(f"Variable {var} has no valid values in one or both datasets")
                continue
            
            # create bins based on baseline distribution
            if bin_method.lower() == 'quantile':
                # use quantiles from baseline to create bins
                bin_edges = np.percentile(baseline_vals, np.linspace(0, 100, n_bins + 1))
                # handle duplicate edges (can happen with categorical-like data)
                bin_edges = np.unique(bin_edges)
                if len(bin_edges) < n_bins + 1:
                    warnings.warn(f"Variable {var}: reduced bins due to duplicate values")
            else:  # equal_width
                bin_edges = np.linspace(baseline_vals.min(), baseline_vals.max(), n_bins + 1)
            
            # make sure the edges capture all data
            bin_edges[0] = min(bin_edges[0], baseline_vals.min(), oot_vals.min()) - 0.001
            bin_edges[-1] = max(bin_edges[-1], baseline_vals.max(), oot_vals.max()) + 0.001
            
            # bin both datasets using the same edges
            baseline_bins = pd.cut(baseline_vals, bins=bin_edges, include_lowest=True, duplicates='drop')
            oot_bins = pd.cut(oot_vals, bins=bin_edges, include_lowest=True, duplicates='drop')
            
            # get distribution percentages
            baseline_dist = baseline_bins.value_counts(normalize=True, sort=False)
            oot_dist = oot_bins.value_counts(normalize=True, sort=False)
            
            # make sure both have same index (some bins might be empty)
            all_bins = baseline_dist.index.union(oot_dist.index)
            baseline_pct = baseline_dist.reindex(all_bins, fill_value=0.0)
            oot_pct = oot_dist.reindex(all_bins, fill_value=0.0)
            
            # handle zero percentages (add small value to avoid log issues)
            baseline_pct = np.maximum(baseline_pct, 0.0001)
            oot_pct = np.maximum(oot_pct, 0.0001)
            
            # calculate psi for each bin: (oot% - baseline%) * ln(oot% / baseline%)
            bin_psi = (oot_pct - baseline_pct) * np.log(oot_pct / baseline_pct)
            total_psi = bin_psi.sum()
            
            # create detailed breakdown
            bin_analysis = pd.DataFrame({
                'bin': all_bins.astype(str),
                'baseline_pct': baseline_pct * 100,
                'oot_pct': oot_pct * 100,
                'difference': (oot_pct - baseline_pct) * 100,
                'ln_ratio': np.log(oot_pct / baseline_pct),
                'bin_psi': bin_psi
            })
            
            # interpret psi value
            if total_psi < 0.1:
                interpretation = "Low Risk - No significant change"
            elif total_psi < 0.2:
                interpretation = "Medium Risk - Some change detected"
            else:
                interpretation = "High Risk - Significant population shift"
            
            # basic stats for context
            baseline_stats = {
                'count': len(baseline_vals),
                'mean': baseline_vals.mean(),
                'std': baseline_vals.std(),
                'min': baseline_vals.min(),
                'max': baseline_vals.max()
            }
            
            oot_stats = {
                'count': len(oot_vals),
                'mean': oot_vals.mean(), 
                'std': oot_vals.std(),
                'min': oot_vals.min(),
                'max': oot_vals.max()
            }
            
            results[var] = {
                'psi_value': total_psi,
                'interpretation': interpretation,
                'bin_analysis': bin_analysis,
                'baseline_stats': baseline_stats,
                'oot_stats': oot_stats
            }
            
            # print summary for this variable
            print(f"\nVariable: {var}")
            print(f"  PSI Value: {total_psi:.4f}")
            print(f"  Risk Level: {interpretation}")
            print(f"  Baseline: n={baseline_stats['count']}, mean={baseline_stats['mean']:.4f}")
            print(f"  OOT: n={oot_stats['count']}, mean={oot_stats['mean']:.4f}")
            
            # flag bins with high contribution if psi is concerning
            if total_psi > 0.1:
                high_contrib_bins = bin_analysis[bin_analysis['bin_psi'] > 0.01]
                if len(high_contrib_bins) > 0:
                    print(f"  High contributing bins: {len(high_contrib_bins)}")
            
        except Exception as e:
            warnings.warn(f"Error calculating PSI for variable {var}: {str(e)}")
            continue
    
    if not results:
        print("No valid PSI calculations completed")
    
    return results
